{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class player(object):\n",
    "    def __init__(self, num_arm):\n",
    "        self.num_arm = num_arm\n",
    "        self.count = np.zeros(num_arm)\n",
    "        self.prefer = np.zeros(num_arm)\n",
    "        self.inf = 1000000\n",
    "        self.rankings = np.ones(num_arm) * self.inf\n",
    "\n",
    "    def update(self, reward, arm_index, round):\n",
    "        self.count[arm_index] += 1\n",
    "        self.prefer[arm_index] += self.count[arm_index] * (reward - self.prefer[arm_index])\n",
    "        self.rankings[arm_index] = self.prefer[arm_index] + np.sqrt(3 * np.log(round) / (2 * self.count[arm_index]))\n",
    "    \n",
    "    def rankings(self):\n",
    "        return np.argsort(-self.rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arm(object):\n",
    "    def __init__(self, num_player, mean, var):\n",
    "        self.num_player = num_player\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self.ranking = np.zeros(num_player)\n",
    "\n",
    "    def set_prefer(self, ranking_list):\n",
    "        self.ranking = np.array(ranking_list)\n",
    "\n",
    "    def rankings(self):\n",
    "        return self.ranking\n",
    "    \n",
    "    def gene_reward(self, player_num):\n",
    "        return np.random.normal(self.mean[player_num], self.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class platform(object):\n",
    "    def __init__(self, num_players, num_arms):\n",
    "        self.num_players = num_players\n",
    "        self.num_arms = num_arms\n",
    "        self.round = 0 \n",
    "    \n",
    "    def update_round(self):\n",
    "        self.round += 1\n",
    "\n",
    "    def GS(self, players, arms):\n",
    "        players_to_arms = np.zeros([self.num_players, self.num_arms])\n",
    "        arms_to_players = np.zeros([self.num_arms, self.num_players])\n",
    "        for i in self.num_players:\n",
    "            players_to_arms[i] = players[i].rankings()\n",
    "        for i in self.num_arms:\n",
    "            arms_to_players = arms[i].rankings()\n",
    "        \n",
    "        # trajectory records the proposing, match_or_not record single or not, \n",
    "        # match_buffer records all people who propose same arm\n",
    "        trajectory = np.zeros(self.num_players)\n",
    "        matching_or_not = np.zeros(self.num_players)\n",
    "        matching_buffer = []\n",
    "        for i in range(self.num_arms):\n",
    "            matching_buffer.append([])\n",
    "\n",
    "        while True:\n",
    "            if np.sum(matching_or_not) == num_player:\n",
    "                break\n",
    "\n",
    "            #firstly let all players propose\n",
    "            for p in range(self.num_players):\n",
    "                if matching_or_not[p] == 0:\n",
    "                    p_choice = players_to_arms[p][trajectory[p]]\n",
    "                    matching_buffer[p_choice].append(p)\n",
    "            \n",
    "            #secondly each arm needs to choose the best\n",
    "            for a in range(arms):\n",
    "                if len(matching_buffer[a]) != 0:\n",
    "                    #get the best choice\n",
    "                    for i in range(self.num_players):\n",
    "                        flag = False\n",
    "                        for j in matching_buffer[a]:\n",
    "                            flag = arms_to_players[a][i] == j\n",
    "                            if flag == True:\n",
    "                                break\n",
    "                        if flag == True:\n",
    "                            a_choice = arms_to_players[a][i]\n",
    "                            break\n",
    "                    #update player\n",
    "                    for p_ in match_buffer[a]:\n",
    "                        if p_ == a_choice:\n",
    "                            matching_or_not[p_] = 1\n",
    "                        else:\n",
    "                            matching_or_not[p_] = 0\n",
    "                            trajectory[p_] += 1\n",
    "                    #update arm\n",
    "                    matching_buffer[a] = a_choice\n",
    "\n",
    "        return matching_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_PLAYERS = 3\n",
    "NUM_ARMS = 3\n",
    "MEAN_ARMS =[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = []\n",
    "for i in range(NUM_PLAYERS):\n",
    "    players.append(player(NUM_PLAYERS))\n",
    "arms = []\n",
    "arms.append(arm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594105553813",
   "display_name": "Python 3.7.7 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}